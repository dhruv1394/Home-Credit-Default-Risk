{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;font-size:30px;\" >Home Credit Default Risk : Flask API Deployment Pipeline</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Importing the Necessary Libraries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Class which has all the Necessary Functions Defined</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class initial_function_definition:\n",
    "    \n",
    "    def reduce_memory_usage(df):\n",
    "  \n",
    "        start_mem = df.memory_usage().sum() / 1024**2\n",
    "        print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtype\n",
    "        \n",
    "            if col_type != object:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "    def fix_nulls_outliers(data):\n",
    "    \n",
    "        #Replace NA with the most frequently occuring class for Count of Client Family Members\n",
    "        data['CNT_FAM_MEMBERS'].fillna(data['CNT_FAM_MEMBERS'].value_counts().idxmax(), \\\n",
    "                                     inplace=True)\n",
    "        data.replace(max(data['DAYS_EMPLOYED'].values), np.nan, inplace=True)\n",
    "        data['NAME_FAMILY_STATUS'].fillna('Data_Not_Available', inplace=True)\n",
    "        data['NAME_HOUSING_TYPE'].fillna('Data_Not_Available', inplace=True)\n",
    "        data['FLAG_MOBIL'].fillna('Data_Not_Available', inplace=True)\n",
    "        data['FLAG_EMP_PHONE'].fillna('Data_Not_Available', inplace=True)\n",
    "        data['FLAG_CONT_MOBILE'].fillna('Data_Not_Available', inplace=True)\n",
    "        data['FLAG_EMAIL'].fillna('Data_Not_Available', inplace=True)\n",
    "        data['OCCUPATION_TYPE'].fillna('Data_Not_Available', inplace=True)\n",
    "\n",
    "        #Replace NA with the most frequently occuring class for Count of Client Family Members\n",
    "        data['CNT_FAM_MEMBERS'].fillna(data['CNT_FAM_MEMBERS'].value_counts().idxmax(), \\\n",
    "                                             inplace=True)\n",
    "        data.replace(max(data['DAYS_EMPLOYED'].values), np.nan, inplace=True)\n",
    "\n",
    "        data['CODE_GENDER'].replace('XNA','M',inplace=True)\n",
    "        data['AMT_ANNUITY'].fillna(0, inplace=True)\n",
    "        data['AMT_GOODS_PRICE'].fillna(0, inplace=True)\n",
    "        data['NAME_TYPE_SUITE'].fillna('Unaccompanied', inplace=True)\n",
    "        data['NAME_FAMILY_STATUS'].replace('Unknown','Married', inplace=True)\n",
    "        data['OCCUPATION_TYPE'].fillna('Data_Not_Available', inplace=True)\n",
    "\n",
    "        data['EXT_SOURCE_1'].fillna(0, inplace=True)\n",
    "        data['EXT_SOURCE_2'].fillna(0, inplace=True)\n",
    "        data['EXT_SOURCE_3'].fillna(0, inplace=True)\n",
    "    \n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "    def FE_application_data(data):\n",
    "    \n",
    "        data['CREDIT_INCOME_PERCENT'] = data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n",
    "        data['ANNUITY_INCOME_PERCENT'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "        data['CREDIT_ANNUITY_PERCENT'] = data['AMT_CREDIT'] / data['AMT_ANNUITY']\n",
    "\n",
    "        data['FAMILY_CNT_INCOME_PERCENT'] = data['AMT_INCOME_TOTAL'] / data['CNT_FAM_MEMBERS']\n",
    "        data['CREDIT_TERM'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "        data['BIRTH_EMPLOYED_PERCENT'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "        data['CHILDREN_CNT_INCOME_PERCENT'] = data['AMT_INCOME_TOTAL']/data['CNT_CHILDREN']\n",
    "\n",
    "        data['CREDIT_GOODS_DIFF'] = data['AMT_CREDIT'] - data['AMT_GOODS_PRICE']\n",
    "        data['EMPLOYED_REGISTRATION_PERCENT'] = data['DAYS_EMPLOYED'] / data['DAYS_REGISTRATION']\n",
    "        data['BIRTH_REGISTRATION_PERCENT'] = data['DAYS_BIRTH'] / data['DAYS_REGISTRATION']\n",
    "        data['ID_REGISTRATION_DIFF'] = data['DAYS_ID_PUBLISH'] - data['DAYS_REGISTRATION']\n",
    "\n",
    "        data['ANNUITY_LENGTH_EMPLOYED_PERCENT'] = data['CREDIT_TERM']/ data['DAYS_EMPLOYED']\n",
    "\n",
    "        data['AGE_LOAN_FINISH'] = data['DAYS_BIRTH']*(-1.0/365) + \\\n",
    "                         (data['AMT_CREDIT']/data['AMT_ANNUITY']) *(1.0/12)\n",
    "        #(This basically refers to the client's age when he/she finishes loan repayment)\n",
    "\n",
    "        data['CAR_AGE_EMP_PERCENT'] = data['OWN_CAR_AGE']/data['DAYS_EMPLOYED']\n",
    "        data['CAR_AGE_BIRTH_PERCENT'] = data['OWN_CAR_AGE']/data['DAYS_BIRTH']\n",
    "        data['PHONE_CHANGE_EMP_PERCENT'] = data['DAYS_LAST_PHONE_CHANGE']/data['DAYS_EMPLOYED']\n",
    "        data['PHONE_CHANGE_BIRTH_PERCENT'] = data['DAYS_LAST_PHONE_CHANGE']/data['DAYS_BIRTH']\n",
    "    \n",
    "        income_by_contract = data[['AMT_INCOME_TOTAL', 'NAME_CONTRACT_TYPE']].groupby('NAME_CONTRACT_TYPE').median()['AMT_INCOME_TOTAL']\n",
    "        data['MEDIAN_INCOME_CONTRACT_TYPE'] = data['NAME_CONTRACT_TYPE'].map(income_by_contract)\n",
    "    \n",
    "        income_by_suite = data[['AMT_INCOME_TOTAL', 'NAME_TYPE_SUITE']].groupby('NAME_TYPE_SUITE').median()['AMT_INCOME_TOTAL']\n",
    "        data['MEDIAN_INCOME_SUITE_TYPE'] = data['NAME_TYPE_SUITE'].map(income_by_suite)\n",
    "    \n",
    "        income_by_housing = data[['AMT_INCOME_TOTAL', 'NAME_HOUSING_TYPE']].groupby('NAME_HOUSING_TYPE').median()['AMT_INCOME_TOTAL']\n",
    "        data['MEDIAN_INCOME_HOUSING_TYPE'] = data['NAME_HOUSING_TYPE'].map(income_by_housing)\n",
    "    \n",
    "        income_by_org = data[['AMT_INCOME_TOTAL', 'ORGANIZATION_TYPE']].groupby('ORGANIZATION_TYPE').median()['AMT_INCOME_TOTAL']\n",
    "        data['MEDIAN_INCOME_ORG_TYPE'] = data['ORGANIZATION_TYPE'].map(income_by_org)\n",
    "\n",
    "        income_by_occu = data[['AMT_INCOME_TOTAL', 'OCCUPATION_TYPE']].groupby('OCCUPATION_TYPE').median()['AMT_INCOME_TOTAL']\n",
    "        data['MEDIAN_INCOME_OCCU_TYPE'] = data['OCCUPATION_TYPE'].map(income_by_occu)\n",
    "\n",
    "        income_by_education = data[['AMT_INCOME_TOTAL', 'NAME_EDUCATION_TYPE']].groupby('NAME_EDUCATION_TYPE').median()['AMT_INCOME_TOTAL']\n",
    "        data['MEDIAN_INCOME_EDU_TYPE'] = data['NAME_EDUCATION_TYPE'].map(income_by_education)\n",
    "\n",
    "        data['ORG_TYPE_INCOME_PERCENT'] = data['MEDIAN_INCOME_ORG_TYPE']/data['AMT_INCOME_TOTAL']\n",
    "        data['OCCU_TYPE_INCOME_PERCENT'] = data['MEDIAN_INCOME_OCCU_TYPE']/data['AMT_INCOME_TOTAL']\n",
    "        data['EDU_TYPE_INCOME_PERCENT'] = data['MEDIAN_INCOME_EDU_TYPE']/data['AMT_INCOME_TOTAL']\n",
    "\n",
    "        data= data.drop(['FLAG_DOCUMENT_2','FLAG_DOCUMENT_4','FLAG_DOCUMENT_5','FLAG_DOCUMENT_6','FLAG_DOCUMENT_7',\n",
    "        'FLAG_DOCUMENT_8','FLAG_DOCUMENT_9','FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11','FLAG_DOCUMENT_12','FLAG_DOCUMENT_13',\n",
    "        'FLAG_DOCUMENT_14','FLAG_DOCUMENT_15','FLAG_DOCUMENT_16','FLAG_DOCUMENT_17','FLAG_DOCUMENT_18','FLAG_DOCUMENT_19',\n",
    "        'FLAG_DOCUMENT_20','FLAG_DOCUMENT_21'],axis=1)\n",
    "\n",
    "        cat_col = [category for category in data.columns if data[category].dtype == 'object']\n",
    "        data = pd.get_dummies(data, columns= cat_col)\n",
    "    \n",
    "        return data\n",
    "\n",
    "\n",
    "    def one_hot_encode(df):\n",
    "\n",
    "        original_columns = list(df.columns)\n",
    "        categories = [cat for cat in df.columns if df[cat].dtype == 'object']\n",
    "        df = pd.get_dummies(df, columns= categories, dummy_na= True) #one_hot_encode the categorical features\n",
    "        categorical_columns = [cat for cat in df.columns if cat not in original_columns]\n",
    "        return df, categorical_columns\n",
    "\n",
    "\n",
    "    def generate_credit_type_code(x):\n",
    "\n",
    "        if x == 'Closed':\n",
    "            y = 0\n",
    "        elif x=='Active':\n",
    "            y = 1\n",
    "        else:\n",
    "            y = 2    \n",
    "        return y\n",
    "\n",
    "\n",
    "    def FE_bureau_data_1(bureau_data):\n",
    "\n",
    "        bureau_data['CREDIT_DURATION'] = -bureau_data['DAYS_CREDIT'] + bureau_data['DAYS_CREDIT_ENDDATE'] \n",
    "        bureau_data['ENDDATE_DIFF'] = bureau_data['DAYS_CREDIT_ENDDATE'] - bureau_data['DAYS_ENDDATE_FACT']\n",
    "        bureau_data['UPDATE_DIFF'] = bureau_data['DAYS_CREDIT_ENDDATE'] - bureau_data['DAYS_CREDIT_UPDATE']\n",
    "        bureau_data['DEBT_PERCENTAGE'] = bureau_data['AMT_CREDIT_SUM'] / bureau_data['AMT_CREDIT_SUM_DEBT']\n",
    "        bureau_data['DEBT_CREDIT_DIFF'] = bureau_data['AMT_CREDIT_SUM'] - bureau_data['AMT_CREDIT_SUM_DEBT']\n",
    "        bureau_data['CREDIT_TO_ANNUITY_RATIO'] = bureau_data['AMT_CREDIT_SUM'] / bureau_data['AMT_ANNUITY']\n",
    "        bureau_data['DEBT_TO_ANNUITY_RATIO'] = bureau_data['AMT_CREDIT_SUM_DEBT'] / bureau_data['AMT_ANNUITY']\n",
    "        bureau_data['CREDIT_OVERDUE_DIFF'] = bureau_data['AMT_CREDIT_SUM'] - bureau_data['AMT_CREDIT_SUM_OVERDUE']\n",
    "    \n",
    "        #Refer :- https://www.kaggle.com/c/home-credit-default-risk/discussion/57750\n",
    "        #Calculating the Number of Past Loans for each Customer\n",
    "        no_loans_per_customer = bureau_data[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby(by = \\\n",
    "                                                                    ['SK_ID_CURR'])['SK_ID_BUREAU'].count()\n",
    "        no_loans_per_customer = no_loans_per_customer.reset_index().rename(columns={'SK_ID_BUREAU': 'CUSTOMER_LOAN_COUNT'})\n",
    "        bureau_data = bureau_data.merge(no_loans_per_customer, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "        #Calculating the Past Credit Types per Customer\n",
    "        credit_types_per_customer = bureau_data[['SK_ID_CURR','CREDIT_TYPE']].groupby(by=['SK_ID_CURR'])['CREDIT_TYPE'].nunique()\n",
    "        credit_types_per_customer = credit_types_per_customer.reset_index().rename(columns={'CREDIT_TYPE':'CUSTOMER_CREDIT_TYPES'})\n",
    "        bureau_data = bureau_data.merge(credit_types_per_customer, on='SK_ID_CURR',how='left')\n",
    "    \n",
    "        #Average Loan Type per Customer\n",
    "        bureau_data['AVG_LOAN_TYPE'] = bureau_data['CUSTOMER_LOAN_COUNT']/bureau_data['CUSTOMER_CREDIT_TYPES']\n",
    "    \n",
    "        bureau_data['CREDIT_TYPE_CODE'] = bureau_data.apply(lambda x:\\\n",
    "                                        initial_function_definition.generate_credit_type_code(x.CREDIT_ACTIVE), axis=1)\n",
    "    \n",
    "        customer_credit_code_mean = bureau_data[['SK_ID_CURR','CREDIT_TYPE_CODE']].groupby(by=['SK_ID_CURR'])['CREDIT_TYPE_CODE'].mean()\n",
    "        customer_credit_code_mean.reset_index().rename(columns={'CREDIT_TYPE_CODE':'CUSTOMER_CREDIT_CODE_MEAN'})\n",
    "        bureau_data = bureau_data.merge(customer_credit_code_mean, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "        #Computing the Ratio of Total Customer Credit and the Total Customer Debt\n",
    "        bureau_data['AMT_CREDIT_SUM'] = bureau_data['AMT_CREDIT_SUM'].fillna(0)\n",
    "        bureau_data['AMT_CREDIT_SUM_DEBT'] = bureau_data['AMT_CREDIT_SUM_DEBT'].fillna(0)\n",
    "        bureau_data['AMT_ANNUITY'] = bureau_data['AMT_ANNUITY'].fillna(0)\n",
    "    \n",
    "        credit_sum_customer = bureau_data[['SK_ID_CURR','AMT_CREDIT_SUM']].groupby(by=['SK_ID_CURR'])['AMT_CREDIT_SUM'].sum()\n",
    "        credit_sum_customer = credit_sum_customer.reset_index().rename(columns={'AMT_CREDIT_SUM':'TOTAL_CREDIT_SUM'})\n",
    "        bureau_data = bureau_data.merge(credit_sum_customer, on='SK_ID_CURR', how='left')\n",
    "                                      \n",
    "        credit_debt_sum_customer = bureau_data[['SK_ID_CURR','AMT_CREDIT_SUM_DEBT']].groupby(by=['SK_ID_CURR'])['AMT_CREDIT_SUM_DEBT'].sum()\n",
    "        credit_debt_sum_customer = credit_debt_sum_customer.reset_index().rename(columns={'AMT_CREDIT_SUM_DEBT':'TOTAL_DEBT_SUM'})\n",
    "        bureau_data = bureau_data.merge(credit_debt_sum_customer, on='SK_ID_CURR', how='left')\n",
    "        bureau_data['CREDIT_DEBT_RATIO'] = bureau_data['TOTAL_CREDIT_SUM']/bureau_data['TOTAL_DEBT_SUM']\n",
    "    \n",
    "        return bureau_data\n",
    "\n",
    "\n",
    "    def FE_bureau_data_2(bureau_data,bureau_balance,bureau_data_columns,bureau_balance_columns):\n",
    "\n",
    "        bureau_balance_agg = {'MONTHS_BALANCE': ['min','max','mean','size']}\n",
    "    \n",
    "        for column in bureau_balance_columns:\n",
    "            bureau_balance_agg[column] = ['min','max','mean','size']\n",
    "            bureau_balance_final_agg = bureau_balance.groupby('SK_ID_BUREAU').agg(bureau_balance_agg)\n",
    "    \n",
    "        col_list_1 =[]\n",
    "    \n",
    "        for col in bureau_balance_final_agg.columns.tolist():\n",
    "            col_list_1.append(col[0] + \"_\" + col[1].upper())\n",
    "    \n",
    "        bureau_balance_final_agg.columns = pd.Index(col_list_1)\n",
    "        bureau_data_balance = bureau_data.join(bureau_balance_final_agg, how='left', on='SK_ID_BUREAU')\n",
    "        bureau_data_balance.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "\n",
    "        del bureau_balance_final_agg\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "        numerical_agg = {'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],'AMT_CREDIT_SUM_OVERDUE': ['mean','sum'],\n",
    "        'DAYS_CREDIT': ['mean', 'var'],'DAYS_CREDIT_UPDATE': ['mean','min'],'CREDIT_DAY_OVERDUE': ['mean','min'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['mean'],'CNT_CREDIT_PROLONG': ['sum'],'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],'AMT_CREDIT_MAX_OVERDUE': ['mean','max'],\n",
    "        'AMT_ANNUITY': ['max', 'mean','sum'],'AMT_CREDIT_SUM': ['mean', 'sum','max']}\n",
    "\n",
    "        categorical_agg = {}\n",
    "\n",
    "        for col in bureau_data_columns:\n",
    "            categorical_agg[col] = ['mean']\n",
    "            categorical_agg[col] = ['max']\n",
    "\n",
    "        for col in bureau_balance_columns:\n",
    "            categorical_agg[col + \"_MEAN\"] = ['mean']\n",
    "            categorical_agg[col + \"_MIN\"] = ['min']\n",
    "            categorical_agg[col + \"_MAX\"] = ['max']\n",
    "    \n",
    "        bureau_data_balance_2 = bureau_data_balance.groupby('SK_ID_CURR').agg({**numerical_agg,\\\n",
    "                                                                       **categorical_agg})\n",
    "        col_list_2=[]\n",
    "    \n",
    "        for col in bureau_data_balance_2.columns.tolist():\n",
    "            col_list_2.append('BUREAU_'+col[0]+'_'+col[1])\n",
    "        bureau_data_balance_2.columns = pd.Index(col_list_2)   \n",
    "\n",
    "\n",
    "        bureau_data_balance_3 = bureau_data_balance[bureau_data_balance['CREDIT_ACTIVE_Active'] == 1]\n",
    "        bureau_data_balance_3_agg = bureau_data_balance_3.groupby('SK_ID_CURR').agg(numerical_agg)\n",
    "\n",
    "        col_list_3=[]\n",
    "\n",
    "        for col in bureau_data_balance_3_agg.columns.tolist():\n",
    "            col_list_3.append('A_'+col[0]+'_'+col[1].upper())\n",
    "\n",
    "        bureau_data_balance_3_agg.columns = pd.Index(col_list_3)\n",
    "        b3_final = bureau_data_balance_2.join(bureau_data_balance_3_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "        bureau_data_balance_4 = bureau_data_balance[bureau_data_balance['CREDIT_ACTIVE_Closed'] == 1]\n",
    "        bureau_data_balance_4_agg = bureau_data_balance_4.groupby('SK_ID_CURR').agg(numerical_agg)\n",
    "\n",
    "        col_list_4 =[]\n",
    "    \n",
    "        for col in bureau_data_balance_4_agg.columns.tolist():\n",
    "            col_list_4.append('C_'+col[0]+'_'+col[1].upper())\n",
    "\n",
    "        bureau_data_balance_4_agg.columns = pd.Index(col_list_4)\n",
    "        bureau_data_balance_final = bureau_data_balance_2.join(bureau_data_balance_4_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "        del bureau_data_balance_3, bureau_data_balance_4_agg\n",
    "        gc.collect()\n",
    "    \n",
    "        return bureau_data_balance_final\n",
    "\n",
    "\n",
    "\n",
    "    def preprocess_previous_application(data):\n",
    "    \n",
    "        data['DAYS_FIRST_DRAWING'].replace(max(data['DAYS_FIRST_DRAWING'].values),np.nan, inplace=True)\n",
    "        data['DAYS_FIRST_DUE'].replace(np.nan,0, inplace= True)\n",
    "        data['DAYS_FIRST_DUE'].replace(0,np.nan, inplace= True)\n",
    "        data['DAYS_FIRST_DUE'].replace(max(data['DAYS_FIRST_DUE'].values),np.nan, inplace=True)\n",
    "\n",
    "        data['DAYS_LAST_DUE_1ST_VERSION'].replace(np.nan,0, inplace= True)\n",
    "        data['DAYS_LAST_DUE_1ST_VERSION'].replace(0,np.nan, inplace= True)\n",
    "        data['DAYS_LAST_DUE_1ST_VERSION'].replace(max(data['DAYS_LAST_DUE_1ST_VERSION'].values),np.nan, inplace=True)\n",
    "\n",
    "        data['DAYS_LAST_DUE'].replace(np.nan,0, inplace= True)\n",
    "        data['DAYS_LAST_DUE'].replace(0,np.nan, inplace= True)\n",
    "        data['DAYS_LAST_DUE'].replace(max(data['DAYS_LAST_DUE'].values),np.nan, inplace=True)\n",
    "\n",
    "        data['DAYS_TERMINATION'].replace(np.nan,0, inplace= True)\n",
    "        data['DAYS_TERMINATION'].replace(0,np.nan, inplace= True)\n",
    "        data['DAYS_TERMINATION'].replace(max(data['DAYS_TERMINATION'].values),np.nan, inplace=True)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "    def FE_previous_application(previous_application):\n",
    "    \n",
    "        prev_app, previous_application_columns = initial_function_definition.one_hot_encode(previous_application)\n",
    "    \n",
    "        prev_app['APPLICATION_CREDIT_DIFF'] = prev_app['AMT_APPLICATION'] - prev_app['AMT_CREDIT']\n",
    "        prev_app['APPLICATION_CREDIT_RATIO'] = prev_app['AMT_APPLICATION'] / prev_app['AMT_CREDIT']\n",
    "        prev_app['CREDIT_TO_ANNUITY_RATIO'] = prev_app['AMT_CREDIT']/prev_app['AMT_ANNUITY']\n",
    "        prev_app['DOWN_PAYMENT_TO_CREDIT'] = prev_app['AMT_DOWN_PAYMENT'] / prev_app['AMT_CREDIT']\n",
    "\n",
    "        total_payment = prev_app['AMT_ANNUITY'] * prev_app['CNT_PAYMENT']\n",
    "        prev_app['SIMPLE_INTERESTS'] = (total_payment/prev_app['AMT_CREDIT'] - 1)/prev_app['CNT_PAYMENT']\n",
    "\n",
    "        prev_app['DAYS_LAST_DUE_DIFF'] = prev_app['DAYS_LAST_DUE_1ST_VERSION'] - prev_app['DAYS_LAST_DUE']\n",
    "\n",
    "        numerical_agg_prev = {'AMT_ANNUITY': ['max', 'mean'], 'AMT_APPLICATION': ['max','mean'],\\\n",
    "                     'AMT_CREDIT':['max','mean'], 'AMT_DOWN_PAYMENT': ['max','mean'],\\\n",
    "                      'AMT_GOODS_PRICE':['mean','sum'], 'HOUR_APPR_PROCESS_START' :\\\n",
    "                      ['max','mean'], 'RATE_DOWN_PAYMENT':['max','mean'], 'RATE_INTEREST_PRIMARY':\\\n",
    "                      ['max','mean'],'RATE_INTEREST_PRIVILEGED':['max','mean'], \\\n",
    "                      'DAYS_DECISION': ['max','mean'], 'CNT_PAYMENT' :['mean','sum'], \\\n",
    "                      'DAYS_FIRST_DRAWING': ['max','mean'], 'DAYS_TERMINATION' : ['max','mean'],\\\n",
    "                      'APPLICATION_CREDIT_RATIO': ['max','mean'], 'DOWN_PAYMENT_TO_CREDIT' : \\\n",
    "                      ['max','mean'], 'DAYS_LAST_DUE_DIFF': ['max','mean']}\n",
    "\n",
    "        categorical_agg_prev = {}\n",
    "    \n",
    "        for column in previous_application_columns:\n",
    "            categorical_agg_prev[column] = ['mean']\n",
    "    \n",
    "        prev_app_agg1 = prev_app.groupby('SK_ID_CURR').agg({**numerical_agg_prev, **categorical_agg_prev})\n",
    "\n",
    "        col_list_5 =[]\n",
    "    \n",
    "        for col in prev_app_agg1.columns.tolist():\n",
    "            col_list_5.append('PREV_'+col[0]+'_'+col[1].upper())\n",
    "\n",
    "        prev_app_agg1.columns = pd.Index(col_list_5)\n",
    "    \n",
    "        prev_app_cs_approved = prev_app[prev_app['NAME_CONTRACT_STATUS_Approved']==1]\n",
    "        prev_app_agg2 = prev_app_cs_approved.groupby('SK_ID_CURR').agg(numerical_agg_prev)\n",
    "\n",
    "        col_list_6 = []\n",
    "\n",
    "        for col in prev_app_agg2.columns.tolist():\n",
    "            col_list_6.append('CS_APP_' + col[0] + '_' + col[1].upper())\n",
    "    \n",
    "        prev_app_agg2.columns = pd.Index(col_list_6)\n",
    "        prev_app_agg1_join = prev_app_agg1.join(prev_app_agg2, how='left', on='SK_ID_CURR')\n",
    "\n",
    "        prev_app_cs_refused = prev_app[prev_app['NAME_CONTRACT_STATUS_Refused']==1]\n",
    "        prev_app_agg3 = prev_app_cs_refused.groupby('SK_ID_CURR').agg(numerical_agg_prev)\n",
    "    \n",
    "        col_list_7 =[]\n",
    "\n",
    "        for col in prev_app_agg3.columns.tolist():\n",
    "            col_list_7.append('CS_REF_' + col[0] + '_' + col[1].upper())\n",
    "\n",
    "        prev_app_agg3.columns = pd.Index(col_list_7)\n",
    "        prev_app_agg_final = prev_app_agg1_join.join(prev_app_agg3,how='left', on='SK_ID_CURR')\n",
    "    \n",
    "        del prev_app_agg1_join, prev_app_agg3, prev_app_cs_refused, prev_app_agg1, prev_app_agg2,prev_app_cs_approved\n",
    "        gc.collect()\n",
    "\n",
    "        return prev_app_agg_final\n",
    "\n",
    "\n",
    "\n",
    "    def FE_previous_application_days_decision(data,data_temp,previous_application):\n",
    "    \n",
    "        temp_1 = initial_function_definition.FE_previous_application(initial_function_definition.reduce_memory_usage(previous_application))\n",
    "        data = data_temp.merge(temp_1, how='left', on='SK_ID_CURR')\n",
    "        del temp_1\n",
    "        gc.collect()\n",
    "\n",
    "        temp_2 = initial_function_definition.reduce_memory_usage(previous_application[previous_application['DAYS_DECISION']>=-365].reset_index())\n",
    "        temp_2.drop(['index'], axis=1, inplace=True)\n",
    "        temp_2 = initial_function_definition.FE_previous_application(temp_2)\n",
    "        data = data.join(temp_2, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
    "        del temp_2\n",
    "        gc.collect()\n",
    "\n",
    "        temp_3 = initial_function_definition.reduce_memory_usage(previous_application[previous_application['DAYS_DECISION']>=-182].reset_index())\n",
    "        temp_3.drop(['index'], axis=1, inplace=True)\n",
    "        temp_3 = initial_function_definition.FE_previous_application(temp_3)\n",
    "        data = data.join(temp_3, how='left', on='SK_ID_CURR', rsuffix='_half_year')\n",
    "        del temp_3\n",
    "        gc.collect()\n",
    "\n",
    "        temp_4 = initial_function_definition.reduce_memory_usage(previous_application[previous_application['DAYS_DECISION']>=-90].reset_index())\n",
    "        temp_4.drop(['index'], axis=1, inplace=True)\n",
    "        temp_4 = initial_function_definition.FE_previous_application(temp_4)\n",
    "        data = data.join(temp_4, how='left', on='SK_ID_CURR', rsuffix='_quarter')\n",
    "        del temp_4\n",
    "        gc.collect()\n",
    "\n",
    "        temp_5 = initial_function_definition.reduce_memory_usage(previous_application[previous_application['DAYS_DECISION']>=-30].reset_index())\n",
    "        temp_5.drop(['index'], axis=1, inplace=True)\n",
    "        temp_5 = initial_function_definition.FE_previous_application(temp_5)\n",
    "        data = data.join(temp_5, how='left', on='SK_ID_CURR', rsuffix='_month')\n",
    "        del temp_5\n",
    "        gc.collect()\n",
    "\n",
    "        temp_6 = initial_function_definition.reduce_memory_usage(previous_application[previous_application['DAYS_DECISION']>=-14].reset_index())\n",
    "        temp_6.drop(['index'], axis=1, inplace=True)\n",
    "        temp_6 = initial_function_definition.FE_previous_application(temp_6)\n",
    "        data = data.join(temp_6, how='left', on='SK_ID_CURR', rsuffix='_fortnight')\n",
    "        del temp_6\n",
    "        gc.collect()\n",
    "\n",
    "        temp_7 = initial_function_definition.reduce_memory_usage(previous_application[previous_application['DAYS_DECISION']>=-7].reset_index())\n",
    "        temp_7.drop(['index'], axis=1, inplace=True)\n",
    "        temp_7 = initial_function_definition.FE_previous_application(temp_7)\n",
    "        data = data.join(temp_7, how='left', on='SK_ID_CURR', rsuffix='_week')\n",
    "        del temp_7\n",
    "        gc.collect()\n",
    "    \n",
    "        return data\n",
    "\n",
    "\n",
    "    def FE_pos_cash_balance(pos_cash_balance):\n",
    "    \n",
    "        pos_balance_data, pos_balance_columns = initial_function_definition.one_hot_encode(pos_cash_balance)\n",
    "    \n",
    "        pos_balance_data['LATE_PAYMENT'] = pos_balance_data['SK_DPD'].apply(lambda x:1 if x>0 else 0)\n",
    "\n",
    "        numerical_agg_pos_balance = {'SK_DPD_DEF': ['max', 'mean','min'],'SK_DPD': ['max', 'mean','min'],\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'], 'CNT_INSTALMENT': ['max','size'],\n",
    "        'CNT_INSTALMENT_FUTURE': ['max','size','sum']}\n",
    "\n",
    "        categorical_agg_pos_balance = {}\n",
    "\n",
    "        for col in pos_balance_columns:\n",
    "            categorical_agg_pos_balance[col] = ['mean']\n",
    "\n",
    "        pos_balance_agg = pos_balance_data.groupby('SK_ID_CURR').agg({**numerical_agg_pos_balance, **categorical_agg_pos_balance})\n",
    "\n",
    "        col_list_8=[]\n",
    "\n",
    "        for col in pos_balance_agg.columns.tolist():\n",
    "            col_list_8.append('POS_'+col[0] + '_' + col[1].upper())\n",
    "\n",
    "        pos_balance_agg.columns = pd.Index(col_list_8)\n",
    "\n",
    "        sort_pos_balance = pos_balance_data.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n",
    "        pos_group = sort_pos_balance.groupby('SK_ID_PREV')\n",
    "    \n",
    "        pos_final_df = pd.DataFrame()\n",
    "        pos_final_df['SK_ID_CURR'] = pos_group['SK_ID_CURR'].first()\n",
    "        pos_final_df['MONTHS_BALANCE_MAX'] = pos_group['MONTHS_BALANCE'].max()\n",
    "    \n",
    "        pos_final_df['POS_LOAN_COMPLETED_MEAN'] = pos_group['NAME_CONTRACT_STATUS_Completed'].mean()\n",
    "        pos_final_df['POS_COMPLETED_BEFORE_MEAN'] = pos_group['CNT_INSTALMENT'].first() - pos_group['CNT_INSTALMENT'].last()\n",
    "\n",
    "        pos_final_df['POS_COMPLETED_BEFORE_MEAN'] = pos_final_df.apply(lambda x: 1 if x['POS_COMPLETED_BEFORE_MEAN'] > 0\n",
    "                                                and x['POS_LOAN_COMPLETED_MEAN'] > 0 else 0, axis=1)\n",
    "    \n",
    "        pos_final_df['POS_REMAINING_INSTALMENTS'] = pos_group['CNT_INSTALMENT_FUTURE'].last()\n",
    "        pos_final_df['POS_REMAINING_INSTALMENTS_RATIO'] = pos_group['CNT_INSTALMENT_FUTURE'].last()/pos_group['CNT_INSTALMENT'].last()\n",
    "    \n",
    "        pos_final_df_groupby = pos_final_df.groupby('SK_ID_CURR').sum().reset_index()\n",
    "        pos_final_df_groupby.drop(['MONTHS_BALANCE_MAX'], axis=1, inplace= True)\n",
    "        pos_final_agg = pd.merge(pos_balance_agg, pos_final_df_groupby, on= 'SK_ID_CURR', how= 'left')\n",
    "    \n",
    "        del pos_balance_agg, pos_final_df_groupby, pos_group, sort_pos_balance\n",
    "        gc.collect()\n",
    "        return pos_final_agg\n",
    "\n",
    "\n",
    "    def FE_pos_cash_balance_months_balance(data, data_temp, pos_cash_balance):\n",
    "    \n",
    "        temp_8 = initial_function_definition.FE_pos_cash_balance(initial_function_definition.reduce_memory_usage(pos_cash_balance))\n",
    "        data = data_temp.merge(temp_8, how='left', on='SK_ID_CURR')\n",
    "        del temp_8\n",
    "        gc.collect()\n",
    "\n",
    "        temp_9 = initial_function_definition.reduce_memory_usage(pos_cash_balance[pos_cash_balance['MONTHS_BALANCE']>=-12].reset_index())\n",
    "        temp_9.drop(['index'], axis=1, inplace=True)\n",
    "        temp_9 = initial_function_definition.FE_pos_cash_balance(temp_9)\n",
    "        data = data.join(temp_9, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
    "        del temp_9\n",
    "        gc.collect()\n",
    "\n",
    "        temp_10 = initial_function_definition.reduce_memory_usage(pos_cash_balance[pos_cash_balance['MONTHS_BALANCE']>=-6].reset_index())\n",
    "        temp_10.drop(['index'], axis=1, inplace=True)\n",
    "        temp_10 = initial_function_definition.FE_pos_cash_balance(temp_10)\n",
    "        data = data.join(temp_10, how='left', on='SK_ID_CURR', rsuffix='_half_year')\n",
    "        del temp_10\n",
    "        gc.collect()\n",
    "\n",
    "        temp_11 = initial_function_definition.reduce_memory_usage(pos_cash_balance[pos_cash_balance['MONTHS_BALANCE']>=-3].reset_index())\n",
    "        temp_11.drop(['index'], axis=1, inplace=True)\n",
    "        temp_11 = initial_function_definition.FE_pos_cash_balance(temp_11)\n",
    "        data = data.join(temp_11, how='left', on='SK_ID_CURR', rsuffix='_quarter')\n",
    "        del temp_11\n",
    "        gc.collect()\n",
    "\n",
    "        temp_12 = initial_function_definition.reduce_memory_usage(pos_cash_balance[pos_cash_balance['MONTHS_BALANCE']>=-1].reset_index())\n",
    "        temp_12.drop(['index'], axis=1, inplace=True)\n",
    "        temp_12 = initial_function_definition.FE_pos_cash_balance(temp_12)\n",
    "        data = data.join(temp_12, how='left', on='SK_ID_CURR', rsuffix='_month')\n",
    "        del temp_12\n",
    "        gc.collect()\n",
    "    \n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "    def FE_installments_payments(installments_payments):\n",
    "    \n",
    "        pay1 = installments_payments[['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER']+ ['AMT_PAYMENT']]\n",
    "        pay2 = pay1.groupby(['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER'])['AMT_PAYMENT'].sum().reset_index()\n",
    "        pay_final = pay2.rename(columns={'AMT_PAYMENT': 'AMT_PAYMENT_GROUPED'})\n",
    "        payments_final = installments_payments.merge(pay_final,\\\n",
    "                            on=['SK_ID_PREV','NUM_INSTALMENT_NUMBER'], how='left')\n",
    "\n",
    "        payments_final['PAYMENT_DIFFERENCE'] = payments_final['AMT_INSTALMENT'] - payments_final['AMT_PAYMENT_GROUPED']\n",
    "        payments_final['PAYMENT_RATIO'] = payments_final['AMT_INSTALMENT'] / payments_final['AMT_PAYMENT_GROUPED']\n",
    "\n",
    "        payments_final['PAID_OVER_AMOUNT'] = payments_final['AMT_PAYMENT'] - payments_final['AMT_INSTALMENT']\n",
    "        payments_final['PAID_OVER'] = (payments_final['PAID_OVER_AMOUNT'] > 0).astype(int)\n",
    "   \n",
    "        payments_final['DPD'] = payments_final['DAYS_ENTRY_PAYMENT'] - \\\n",
    "                        payments_final['DAYS_INSTALMENT']\n",
    "        payments_final['DPD'] = payments_final['DPD'].apply(lambda x: 0 if x <= 0 else x)\n",
    "\n",
    "        payments_final['DBD'] = payments_final['DAYS_INSTALMENT'] - \\\n",
    "                        payments_final['DAYS_ENTRY_PAYMENT']\n",
    "        payments_final['DBD'] = payments_final['DBD'].apply(lambda x: 0 if x <= 0 else x)\n",
    "        payments_final['LATE_PAYMENT'] = payments_final['DBD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "        payments_final['INSTALMENT_PAYMENT_RATIO'] = payments_final['AMT_PAYMENT'] / payments_final['AMT_INSTALMENT']\n",
    "        payments_final['LATE_PAYMENT_RATIO'] = payments_final.apply(lambda x: x['INSTALMENT_PAYMENT_RATIO'] if x['LATE_PAYMENT'] == 1 else 0, axis=1)\n",
    "\n",
    "        payments_final['SIGNIFICANT_LATE_PAYMENT'] = payments_final['LATE_PAYMENT_RATIO'].apply(lambda x: 1 if x > 0.05 else 0)\n",
    "\n",
    "        payments_final['DPD_7'] = payments_final['DPD'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "        payments_final['DPD_15'] = payments_final['DPD'].apply(lambda x: 1 if x >= 15 else 0)\n",
    "        payments_final['DPD_30'] = payments_final['DPD'].apply(lambda x: 1 if x >= 30 else 0)\n",
    "        payments_final['DPD_60'] = payments_final['DPD'].apply(lambda x: 1 if x >= 60 else 0)\n",
    "        payments_final['DPD_90'] = payments_final['DPD'].apply(lambda x: 1 if x >= 90 else 0)\n",
    "        payments_final['DPD_180'] = payments_final['DPD'].apply(lambda x: 1 if x >= 180 else 0)\n",
    "        payments_final['DPD_WOF'] = payments_final['DPD'].apply(lambda x: 1 if x >= 720 else 0)\n",
    "    \n",
    "        payments_final, pay_final_columns = initial_function_definition.one_hot_encode(payments_final)\n",
    "\n",
    "        numeric_agg_payments = {'LATE_PAYMENT': ['max','mean','min'],'AMT_PAYMENT': ['min', 'max',\\\n",
    "                      'mean', 'sum'], 'NUM_INSTALMENT_VERSION': ['nunique'], \\\n",
    "                      'NUM_INSTALMENT_NUMBER':['max'], 'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_DIFFERENCE': ['max','mean','min','sum'],'DAYS_ENTRY_PAYMENT': ['max', \\\n",
    "        'mean', 'sum'],  'PAID_OVER_AMOUNT': ['max','mean','min']}\n",
    "\n",
    "        for col in pay_final_columns:\n",
    "            numeric_agg_payments[col] = ['mean']\n",
    "    \n",
    "        payments_final_agg = payments_final.groupby('SK_ID_CURR').agg(numeric_agg_payments)\n",
    "        col_list_9=[]\n",
    "\n",
    "        for col in payments_final_agg.columns.tolist():\n",
    "            col_list_9.append('INS_'+col[0]+'_'+col[1].upper())\n",
    "\n",
    "        payments_final_agg.columns = pd.Index(col_list_9)\n",
    "        payments_final_agg['INSTALLATION_COUNT'] = payments_final.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "        del payments_final\n",
    "        gc.collect()\n",
    "    \n",
    "        return payments_final_agg\n",
    "\n",
    "\n",
    "    def FE_installments_payments_days_instalment(data, data_temp, installments_payments):\n",
    "\n",
    "        installments_payments['DAYS_ENTRY_PAYMENT'].fillna(0, inplace=True)\n",
    "        installments_payments['AMT_PAYMENT'].fillna(0.0, inplace=True)\n",
    "\n",
    "        temp_13 = initial_function_definition.FE_installments_payments(initial_function_definition.reduce_memory_usage(installments_payments))\n",
    "        data = data_temp.join(temp_13, how='left', on='SK_ID_CURR')\n",
    "        del temp_13\n",
    "        gc.collect()\n",
    "\n",
    "        temp_14 = initial_function_definition.reduce_memory_usage(installments_payments[installments_payments['DAYS_INSTALMENT']>=-365].reset_index())\n",
    "        temp_14.drop(['index'], axis=1, inplace=True)\n",
    "        temp_14 = initial_function_definition.FE_installments_payments(temp_14)\n",
    "        data = data.join(temp_14, how='left', on='SK_ID_CURR', rsuffix='_year')\n",
    "        del temp_14\n",
    "        gc.collect()\n",
    "\n",
    "        temp_15 = initial_function_definition.reduce_memory_usage(installments_payments[installments_payments['DAYS_INSTALMENT']>=-182].reset_index())\n",
    "        temp_15.drop(['index'], axis=1, inplace=True)\n",
    "        temp_15 = initial_function_definition.FE_installments_payments(temp_15)\n",
    "        data = data.join(temp_15, how='left', on='SK_ID_CURR', rsuffix='_half_year')\n",
    "        del temp_15\n",
    "        gc.collect()\n",
    "\n",
    "        temp_16 = initial_function_definition.reduce_memory_usage(installments_payments[installments_payments['DAYS_INSTALMENT']>=-90].reset_index())\n",
    "        temp_16.drop(['index'], axis=1, inplace=True)\n",
    "        temp_16 = initial_function_definition.FE_installments_payments(temp_16)\n",
    "        data = data.join(temp_16, how='left', on='SK_ID_CURR', rsuffix='_quarter')\n",
    "        del temp_16\n",
    "        gc.collect()\n",
    "\n",
    "        temp_17 = initial_function_definition.reduce_memory_usage(installments_payments[installments_payments['DAYS_INSTALMENT']>=-30].reset_index())\n",
    "        temp_17.drop(['index'], axis=1, inplace=True)\n",
    "        temp_17 = initial_function_definition.FE_installments_payments(temp_17)\n",
    "        data = data.join(temp_17, how='left', on='SK_ID_CURR', rsuffix='_month')\n",
    "        del temp_17\n",
    "        gc.collect()\n",
    "   \n",
    "        temp_18 = initial_function_definition.reduce_memory_usage(installments_payments[installments_payments['DAYS_INSTALMENT']>=-14].reset_index())\n",
    "        temp_18.drop(['index'], axis=1, inplace=True)\n",
    "        temp_18 = initial_function_definition.FE_installments_payments(temp_18)\n",
    "        data = data.join(temp_18, how='left', on='SK_ID_CURR', rsuffix='_fortnight')\n",
    "        del temp_18\n",
    "        gc.collect()\n",
    "\n",
    "        temp_19 = initial_function_definition.reduce_memory_usage(installments_payments[installments_payments['DAYS_INSTALMENT']>=-7].reset_index())\n",
    "        temp_19.drop(['index'], axis=1, inplace=True)\n",
    "        temp_19 = initial_function_definition.FE_installments_payments(temp_19)\n",
    "        data = data.join(temp_19, how='left', on='SK_ID_CURR', rsuffix='_week')\n",
    "        del temp_19\n",
    "        gc.collect()\n",
    "    \n",
    "        return data\n",
    "\n",
    "\n",
    "    def FE_credit_card_balance(credit_card_balance):\n",
    "    \n",
    "        cc_balance_data, cc_balance_columns = initial_function_definition.one_hot_encode(credit_card_balance)\n",
    "        cc_balance_data.rename(columns={'AMT_RECIVABLE': 'AMT_RECEIVABLE'}, inplace=True)\n",
    "\n",
    "        cc_balance_data['LIMIT_USE'] = cc_balance_data['AMT_BALANCE'] / cc_balance_data['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "        cc_balance_data['PAYMENT_DIV_MIN'] = cc_balance_data['AMT_PAYMENT_CURRENT'] / cc_balance_data['AMT_INST_MIN_REGULARITY']\n",
    "        cc_balance_data['LATE_PAYMENT'] = cc_balance_data['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "        cc_balance_data['DRAWING_LIMIT_RATIO'] = cc_balance_data['AMT_DRAWINGS_ATM_CURRENT'] / cc_balance_data['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "\n",
    "        cc_balance_data.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "        cc_balance_data_agg = cc_balance_data.groupby('SK_ID_CURR').agg(['max', 'mean', 'sum', 'var'])\n",
    "    \n",
    "        col_list_9=[]\n",
    "\n",
    "        for col in cc_balance_data_agg.columns.tolist():\n",
    "            col_list_9.append('CR_'+col[0]+'_'+col[1].upper())\n",
    "    \n",
    "        cc_balance_data_agg.columns = pd.Index(col_list_9)\n",
    "\n",
    "        cc_balance_data_agg['CREDIT_COUNT'] = cc_balance_data.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "        del cc_balance_data, cc_balance_columns\n",
    "        gc.collect()\n",
    "    \n",
    "        return cc_balance_data_agg\n",
    "\n",
    "\n",
    "\n",
    "    def FE_credit_card_balance_months_balance(data,data_temp,credit_card_balance):\n",
    "    \n",
    "        temp_20 = initial_function_definition.FE_credit_card_balance(initial_function_definition.reduce_memory_usage(credit_card_balance))\n",
    "        data = data_temp.join(temp_20, how='left', on='SK_ID_CURR')\n",
    "        del temp_20\n",
    "        gc.collect()\n",
    "    \n",
    "        temp_21 = initial_function_definition.reduce_memory_usage(credit_card_balance[credit_card_balance['MONTHS_BALANCE']>=-12].reset_index())\n",
    "        temp_21.drop(['index'], axis=1, inplace=True)\n",
    "        temp_21 = initial_function_definition.FE_credit_card_balance(temp_21)\n",
    "        data = data.join(temp_21, how='left', on='SK_ID_CURR', rsuffix='_year')\n",
    "        del temp_21\n",
    "        gc.collect()\n",
    "\n",
    "        temp_22 = initial_function_definition.reduce_memory_usage(credit_card_balance[credit_card_balance['MONTHS_BALANCE']>=-6].reset_index())\n",
    "        temp_22.drop(['index'], axis=1, inplace=True)\n",
    "        temp_22 = initial_function_definition.FE_credit_card_balance(temp_22)\n",
    "        data = data.join(temp_22, how='left', on='SK_ID_CURR', rsuffix='_half_year')\n",
    "        del temp_22\n",
    "        gc.collect()\n",
    "\n",
    "        temp_23 = initial_function_definition.reduce_memory_usage(credit_card_balance[credit_card_balance['MONTHS_BALANCE']>=-3].reset_index())\n",
    "        temp_23.drop(['index'], axis=1, inplace=True)\n",
    "        temp_23 = initial_function_definition.FE_credit_card_balance(temp_23)\n",
    "        data = data.join(temp_23, how='left', on='SK_ID_CURR', rsuffix='_quarter')\n",
    "        del temp_23\n",
    "        gc.collect()\n",
    "\n",
    "        temp_24 = initial_function_definition.reduce_memory_usage(credit_card_balance[credit_card_balance['MONTHS_BALANCE']>=-1].reset_index())\n",
    "        temp_24.drop(['index'], axis=1, inplace=True)\n",
    "        temp_24 = initial_function_definition.FE_credit_card_balance(temp_24)\n",
    "        data = data.join(temp_24, how='left', on='SK_ID_CURR', rsuffix='_month')\n",
    "        del temp_24\n",
    "        gc.collect()\n",
    "    \n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3. Computing the Probabilities on the Test Dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import os.path\n",
    "import sqlite3\n",
    "import flask\n",
    "\n",
    "from flask import Flask, jsonify, request\n",
    "from lightgbm import LGBMClassifier\n",
    "from sqlalchemy import create_engine\n",
    "from hcdr_model import initial_function_definition\n",
    "\n",
    "if os.path.isfile('pickles/test_data')==False:\n",
    "\n",
    "    train_data = initial_function_definition.reduce_memory_usage(pd.read_csv('home-credit-default-risk/application_train.csv'))\n",
    "    test_data = initial_function_definition.reduce_memory_usage(pd.read_csv('home-credit-default-risk/application_test.csv'))\n",
    "    bureau_data = initial_function_definition.reduce_memory_usage(pd.read_csv('home-credit-default-risk/bureau.csv'))\n",
    "    bureau_balance = initial_function_definition.reduce_memory_usage(pd.read_csv('home-credit-default-risk/bureau_balance.csv'))\n",
    "\n",
    "    bureau_data_fe = initial_function_definition.FE_bureau_data_1(bureau_data)\n",
    "\n",
    "    #One Hot Encoding the Bureau Datasets\n",
    "    bureau_data, bureau_data_columns = initial_function_definition.one_hot_encode(bureau_data_fe)\n",
    "    bureau_balance, bureau_balance_columns = initial_function_definition.one_hot_encode(bureau_balance)\n",
    "\n",
    "    bureau_data_balance_final = initial_function_definition.FE_bureau_data_2(bureau_data, bureau_balance,bureau_data_columns,bureau_balance_columns)\n",
    "\n",
    "    previous_application = initial_function_definition.reduce_memory_usage(pd.read_csv('home-credit-default-risk/previous_application.csv'))\n",
    "    previous_application = initial_function_definition.preprocess_previous_application(previous_application)\n",
    "\n",
    "    pos_cash_balance = initial_function_definition.reduce_memory_usage(pd.read_csv('home-credit-default-risk/POS_CASH_balance.csv'))\n",
    "    installments_payments = initial_function_definition.reduce_memory_usage(pd.read_csv('home-credit-default-risk/installments_payments.csv'))\n",
    "    credit_card_balance = initial_function_definition.reduce_memory_usage(pd.read_csv('home-credit-default-risk/credit_card_balance.csv'))\n",
    "\n",
    "\n",
    "    start = datetime.now()\n",
    "\n",
    "    test_data = initial_function_definition.fix_nulls_outliers(test_data)\n",
    "    test_data_temp_1 = initial_function_definition.FE_application_data(test_data)\n",
    "    bureau_data_balance_final = initial_function_definition.FE_bureau_data_2(bureau_data, bureau_balance,bureau_data_columns,bureau_balance_columns)\n",
    "    test_data_temp_2 = test_data_temp_1.join(bureau_data_balance_final, how='left', on='SK_ID_CURR')\n",
    "\n",
    "\n",
    "    test_data_temp_2 = initial_function_definition.FE_previous_application_days_decision(test_data,test_data_temp_2,previous_application)\n",
    "    test_data_temp_2 = initial_function_definition.FE_pos_cash_balance_months_balance(test_data,test_data_temp_2, pos_cash_balance)\n",
    "    test_data_temp_2 = initial_function_definition.FE_installments_payments_days_instalment(test_data,test_data_temp_2,installments_payments)\n",
    "    test_data_temp_2 = initial_function_definition.FE_credit_card_balance_months_balance(test_data,test_data_mod_temp_2,credit_card_balance)\n",
    "\n",
    "    #Removing any duplicate features, if any are present in the final dataset\n",
    "    test_data = test_data_temp_2.loc[:,~test_data_temp_2.columns.duplicated()]\n",
    "\n",
    "    \n",
    "    print(\"Time taken to run this cell :\", datetime.now() - start)\n",
    "\n",
    "else:\n",
    "\n",
    "    test_data = pd.read_pickle('pickles/test_data')\n",
    "\n",
    "     \n",
    "features_top_df_train = pd.read_pickle('pickles/features_top_df_train.pkl')\n",
    "features_top_df_test = test_data[features_top_df_train.columns]\n",
    "features_top_df_test['SK_ID_CURR'] = test_data['SK_ID_CURR']\n",
    "features_top_df_test['TARGET'] = np.nan\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "#home page\n",
    "@app.route('/', methods = [])\n",
    "def hello_world():\n",
    "    return 'Hello World!'\n",
    "\n",
    "\n",
    "#prediction page\n",
    "@app.route('/index')\n",
    "def index():\n",
    "    return flask.render_template('index.html')\n",
    "\n",
    "\n",
    "#results page\n",
    "@app.route('/predict', methods = ['POST'])\n",
    "def predict():\n",
    "\n",
    "    conn = sqlite3.connect('Home_Credit_DB_Connection.db')\n",
    "    sk_id_curr = request.form.to_dict()['SK_ID_CURR']\n",
    "    sk_id_curr = int(sk_id_curr)\n",
    "\n",
    "    test_datapoint = pd.read_sql_query(f'SELECT * FROM test_data_feats WHERE SK_ID_CURR == {sk_id_curr}', conn)\n",
    "    test_datapoint = test_datapoint.replace([None], np.nan)\n",
    "\n",
    "    with open('lgbm/lgbm_model_500f_3.pickle','rb') as f:\n",
    "        lgbm_model = pickle.load(f)\n",
    "\n",
    "    if os.path.isfile('lgbm/lgbm_best_threshold_500f_api.pkl')==False:\n",
    "\n",
    "        feats = [f for f in features_top_df_train.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "        test_predict = np.zeros(features_top_df_test.shape[0])\n",
    "        test_predict += lgbm_model.predict_proba(features_top_df_test[feats], num_iteration=lgbm_model.best_iteration_)[:, 1] / 5\n",
    "    else:\n",
    "\n",
    "        with open('lgbm/lgbm_test_predict_500f.pkl','rb') as f:\n",
    "            test_predict = pickle.load(f)\n",
    "\n",
    "    threshold = 0.3741018248484985\n",
    "\n",
    "    test_predict_rounded = np.round(test_predict,4)\n",
    "    predicted_class_label = np.where(test_predict_rounded > threshold, 1, 0)\n",
    "\n",
    "    select_index = list(np.where(test_data[\"SK_ID_CURR\"] == sk_id_curr)[0]) \n",
    "    final_class_label = predicted_class_label[select_index[0]]\n",
    "    final_test_predict_rounded = test_predict_rounded[select_index[0]]\n",
    "\n",
    "    if final_class_label == 1:\n",
    "        prediction = 'The customer with this ID is a Potential Defaulter with a probability of {}'.format(final_test_predict_rounded)\n",
    "    else:\n",
    "        prediction = 'The customer with this ID is not a Potential Defaulter with a probability of {}'.format(final_test_predict_rounded)\n",
    "        predicted_proba = 1 - final_test_predict_rounded\n",
    "\n",
    "    return jsonify({'prediction': prediction})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.debug=True\n",
    "    app.run(host='0.0.0.0', port=8080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
